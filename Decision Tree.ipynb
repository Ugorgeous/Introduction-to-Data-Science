{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd3ceb10",
   "metadata": {},
   "source": [
    "## 1.信息增益求解函数"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa24aa8e",
   "metadata": {},
   "source": [
    "### 注："
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4763025e",
   "metadata": {},
   "source": [
    "数据格式（参数'data'）要求：\n",
    "\n",
    "1.为dataframe格式。\n",
    "\n",
    "2.传入的n+1列数据中，前n列为特征列，最后一列为label列。\n",
    "\n",
    "3.数据无缺失值。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e850841",
   "metadata": {},
   "source": [
    "#### 以下为计算数据集D中n个特征对应信息增益的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5f596077",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "336e90d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def information_gain(data):\n",
    "    \n",
    "#计算数据集的信息熵\n",
    "    #标签列的可取值存入label_values\n",
    "    label_values=set(data[data.columns[-1]])  \n",
    "    IE=0\n",
    "    for i in label_values:\n",
    "        IE=IE+(-(((data[data[data.columns[-1]]==i]).shape[0])/data.shape[0])*math.log((((data[data[data.columns[-1]]==i]).shape[0])/data.shape[0]),2))\n",
    "#计算各个特征下的条件熵\n",
    "\n",
    "    #CE记录每个特征的条件熵\n",
    "    CE=[]\n",
    "    \n",
    "#对每一个特征进行计算：\n",
    "    for i in data.columns:\n",
    "        #得到并存入第i个特征的可取值\n",
    "        feature_values=set(data[i])\n",
    "        #将第i个特征中取值为j的样本存入data_by_feature\n",
    "        data_by_feature=[]\n",
    "        for j in feature_values:\n",
    "            data_by_feature.append(data[data[i]==j])\n",
    "    #计算第i个特征的条件熵，存入CE\n",
    "        ce=0\n",
    "        for j in data_by_feature:\n",
    "            ie=0\n",
    "            #计算第i个特征取值j的信息熵，记为ie\n",
    "            for k in label_values:\n",
    "                if (j[j[j.columns[-1]]==k].shape[0])==0:\n",
    "                    ie=0\n",
    "                else:\n",
    "                    ie=ie+(  -((j[j[j.columns[-1]]==k].shape[0])/j.shape[0])*math.log((j[j[j.columns[-1]]==k].shape[0])/j.shape[0],2)  )\n",
    "            ce=ce+(  (j.shape[0]/data.shape[0])*ie  )\n",
    "        CE.append(ce)\n",
    "    CE=pd.DataFrame(CE)\n",
    "    ig=IE-CE\n",
    "    ig.index=data.columns\n",
    "    ig.columns=['information gain']\n",
    "    ig=ig[0:-1]\n",
    "    return ig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cbcb707",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b999c1dc",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c2e3d8",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141733db",
   "metadata": {},
   "source": [
    "## 2. 数据导入与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9058fd05",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7bcf2eb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>色泽</th>\n",
       "      <th>根蒂</th>\n",
       "      <th>敲击</th>\n",
       "      <th>纹理</th>\n",
       "      <th>脐部</th>\n",
       "      <th>触感</th>\n",
       "      <th>是否好瓜</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>青绿</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>好瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>青绿</td>\n",
       "      <td>硬挺</td>\n",
       "      <td>清脆</td>\n",
       "      <td>清晰</td>\n",
       "      <td>平坦</td>\n",
       "      <td>软粘</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>浅白</td>\n",
       "      <td>硬挺</td>\n",
       "      <td>清脆</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>软粘</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>青绿</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>浅白</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>凹陷</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>乌黑</td>\n",
       "      <td>稍蜷</td>\n",
       "      <td>浊响</td>\n",
       "      <td>清晰</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>软粘</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>浅白</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>浊响</td>\n",
       "      <td>模糊</td>\n",
       "      <td>平坦</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>青绿</td>\n",
       "      <td>蜷缩</td>\n",
       "      <td>沉闷</td>\n",
       "      <td>稍糊</td>\n",
       "      <td>稍凹</td>\n",
       "      <td>硬滑</td>\n",
       "      <td>坏瓜</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    色泽  根蒂  敲击  纹理  脐部  触感 是否好瓜\n",
       "0   青绿  蜷缩  浊响  清晰  凹陷  硬滑   好瓜\n",
       "1   乌黑  蜷缩  沉闷  清晰  凹陷  硬滑   好瓜\n",
       "2   乌黑  蜷缩  浊响  清晰  凹陷  硬滑   好瓜\n",
       "3   青绿  蜷缩  沉闷  清晰  凹陷  硬滑   好瓜\n",
       "4   浅白  蜷缩  浊响  清晰  凹陷  硬滑   好瓜\n",
       "5   青绿  稍蜷  浊响  清晰  稍凹  软粘   好瓜\n",
       "6   乌黑  稍蜷  浊响  稍糊  稍凹  软粘   好瓜\n",
       "7   乌黑  稍蜷  浊响  清晰  稍凹  硬滑   好瓜\n",
       "8   乌黑  稍蜷  沉闷  稍糊  稍凹  硬滑   坏瓜\n",
       "9   青绿  硬挺  清脆  清晰  平坦  软粘   坏瓜\n",
       "10  浅白  硬挺  清脆  模糊  平坦  硬滑   坏瓜\n",
       "11  浅白  蜷缩  浊响  模糊  平坦  软粘   坏瓜\n",
       "12  青绿  稍蜷  浊响  稍糊  凹陷  硬滑   坏瓜\n",
       "13  浅白  稍蜷  沉闷  稍糊  凹陷  硬滑   坏瓜\n",
       "14  乌黑  稍蜷  浊响  清晰  稍凹  软粘   坏瓜\n",
       "15  浅白  蜷缩  浊响  模糊  平坦  硬滑   坏瓜\n",
       "16  青绿  蜷缩  沉闷  稍糊  稍凹  硬滑   坏瓜"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data_melon = [\n",
    "        # 1\n",
    "        ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 2\n",
    "        ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 3\n",
    "        ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 4\n",
    "        ['青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 5\n",
    "        ['浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '好瓜'],\n",
    "        # 6\n",
    "        ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '好瓜'],\n",
    "        # 7\n",
    "        ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', '好瓜'],\n",
    "        # 8\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '硬滑', '好瓜'],\n",
    "\n",
    "        # ----------------------------------------------------\n",
    "        # 9\n",
    "        ['乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', '坏瓜'],\n",
    "        # 10\n",
    "        ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', '坏瓜'],\n",
    "        # 11\n",
    "        ['浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', '坏瓜'],\n",
    "        # 12\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', '坏瓜'],\n",
    "        # 13\n",
    "        ['青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', '坏瓜'],\n",
    "        # 14\n",
    "        ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', '坏瓜'],\n",
    "        # 15\n",
    "        ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '坏瓜'],\n",
    "        # 16\n",
    "        ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', '坏瓜'],\n",
    "        # 17\n",
    "        ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', '坏瓜']\n",
    "    ]\n",
    "\n",
    "labels = ['色泽', '根蒂', '敲击', '纹理', '脐部', '触感','是否好瓜']\n",
    "data=pd.DataFrame(data_melon)\n",
    "data.columns=labels\n",
    "display(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1857f0d9",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e591070",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d14eb8c",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d350399a",
   "metadata": {},
   "source": [
    "## 3.计算西瓜数据集2.0的信息增益"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "ae6d09f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>information gain</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>色泽</th>\n",
       "      <td>0.108125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>根蒂</th>\n",
       "      <td>0.142675</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>敲击</th>\n",
       "      <td>0.140781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>纹理</th>\n",
       "      <td>0.380592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>脐部</th>\n",
       "      <td>0.289159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>触感</th>\n",
       "      <td>0.006046</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    information gain\n",
       "色泽          0.108125\n",
       "根蒂          0.142675\n",
       "敲击          0.140781\n",
       "纹理          0.380592\n",
       "脐部          0.289159\n",
       "触感          0.006046"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "information_gain(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47d0314",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37a9ba51",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4e2b5d7",
   "metadata": {},
   "source": [
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddab2588",
   "metadata": {},
   "source": [
    "## 4.ID3决策树的构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "599c5796",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d27b3f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'纹理': {'清晰': {'根蒂': {'蜷缩': '是', '稍蜷': {'色泽': {'青绿': '是', '乌黑': {'触感': {'硬滑': '是', '软粘': '否'}}}}, '硬挺': '否'}}, '稍糊': {'触感': {'软粘': '是', '硬滑': '否'}}, '模糊': '否'}}\n",
      "The truth class is 否, The ID3Tree outcome is 否.\n"
     ]
    }
   ],
   "source": [
    "#序列化与反序列树字典\n",
    "class TreeHandler(object):\n",
    "    def __init__(self):\n",
    "        self.tree = None\n",
    "\n",
    "    def save(self, tree):\n",
    "        self.tree = tree\n",
    "        with open(\"tree.txt\", mode=\"w\", encoding=\"utf-8\") as f:\n",
    "            tree = json.dumps(tree, indent=\"  \", ensure_ascii=False)\n",
    "            f.write(tree)\n",
    "\n",
    "    def load(self, file):\n",
    "        with open(file, mode=\"r\", encoding=\"utf-8\") as f:\n",
    "            tree = f.read()\n",
    "            self.tree = json.loads(tree)\n",
    "        return self.tree\n",
    "\n",
    "\n",
    "class ID3Tree(TreeHandler):\n",
    "    \"\"\"主要的数据结构是pandas对象\"\"\"\n",
    "    __count = 0\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \"\"\"认定最后一列是标签列\"\"\"\n",
    "        self.gain = {}\n",
    "\n",
    "    def _entropy(self, dataSet):\n",
    "        \"\"\"计算给定数据集的熵\"\"\"\n",
    "        labels = list(dataSet.columns)\n",
    "        level_count = dataSet[labels[-1]].value_counts().to_dict()  # 统计分类标签不同水平的值\n",
    "        entropy = 0.0\n",
    "        for key, value in level_count.items():\n",
    "            prob = float(value) / dataSet.shape[0]\n",
    "            entropy += -prob * np.log2(prob)\n",
    "        return entropy\n",
    "\n",
    "    def _split_dataSet(self, dataSet, column, level):\n",
    "        \"\"\"根据给定的column和其level来获取子数据集\"\"\"\n",
    "        subdata = dataSet[dataSet[column] == level]\n",
    "        del subdata[column]  # 删除这个划分字段列\n",
    "        return subdata.reset_index(drop=True)  # 重建索引\n",
    "\n",
    "    def _best_split(self, dataSet):\n",
    "        \"\"\"计算每个分类标签的信息增益\"\"\"\n",
    "        best_info_gain = 0.0  # 求最大信息增益\n",
    "        best_label = None  # 求最大信息增益对应的标签(字段)\n",
    "        labels = list(dataSet.columns)[: -1]  # 不包括最后一个靶标签\n",
    "        init_entropy = self._entropy(dataSet)  # 先求靶标签的香农熵\n",
    "        for _, label in enumerate(labels):\n",
    "            # 根据该label(也即column字段)的唯一值(levels)来切割成不同子数据集，并求它们的香农熵\n",
    "            levels = dataSet[label].unique().tolist()  # 获取该分类标签的不同level\n",
    "            label_entropy = 0.0  # 用于累加各水平的信息熵；分类标签的信息熵等于该分类标签的各水平信息熵与其概率积的和。\n",
    "            for level in levels:  # 循环计算不同水平的信息熵\n",
    "                level_data = dataSet[dataSet[label] == level]  # 获取该水平的数据集\n",
    "                prob = level_data.shape[0] / dataSet.shape[0]  # 计算该水平的数据集在总数据集的占比\n",
    "                # 计算香农熵，并更新到label_entropy中\n",
    "                label_entropy += prob * self._entropy(level_data)  # _entropy用于计算香农熵\n",
    "            # 计算信息增益\n",
    "            info_gain = init_entropy - label_entropy  # 代码至此，已经能够循环计算每个分类标签的信息增益\n",
    "            # 用best_info_gain来取info_gain的最大值，并获取对应的分类标签\n",
    "            if info_gain > best_info_gain:\n",
    "                best_info_gain = info_gain\n",
    "                best_label = label\n",
    "            # 这里保存一下每一次计算的信息增益，便于查看和检查错误\n",
    "            self.gain.setdefault(self.__count, {})  # 建立本次函数调用时的字段，设其value为字典\n",
    "            self.gain[self.__count][label] = info_gain  # 把本次函数调用时计算的各个标签数据存到字典里\n",
    "        self.__count += 1\n",
    "        return best_label\n",
    "\n",
    "    def _top_amount_level(self, target_list):\n",
    "        class_count = target_list.value_counts().to_dict()  # 计算靶标签的不同水平的样本量，并转化为字典\n",
    "        # 字典的items方法可以将键值对转成[(), (), ...]，可以使用列表方法\n",
    "        sorted_class_count = sorted(class_count.items(), key=lambda x: x[1], reverse=True)\n",
    "        return sorted_class_count[0][0]\n",
    "\n",
    "    def mktree(self, dataSet):\n",
    "        \"\"\"创建决策树\"\"\"\n",
    "        target_list = dataSet.iloc[:, -1]  # target_list 靶标签的那一列数据\n",
    "        # 程序终止条件一: 靶标签(数据集的最后一列因变量)在该数据集上只有一个水平，返回该水平\n",
    "        if target_list.unique().shape[0] <= 1:\n",
    "            return target_list[0]  # ！！！\n",
    "        # 程序终止条件二: 数据集只剩下把标签这一列数据；返回数量最多的水平\n",
    "        if dataSet.shape[1] == 1:\n",
    "            return self._top_amount_level(target_list)\n",
    "        # 不满足终止条件时，做如下递归处理\n",
    "        # 1.选择最佳分类标签\n",
    "        best_label = self._best_split(dataSet)\n",
    "        # 2.递归计算最佳分类标签的不同水平的子数据集的信息增益\n",
    "        #   各个子数据集的最佳分类标签的不同水平...\n",
    "        #   ...\n",
    "        #   直至递归结束\n",
    "        best_label_levels = dataSet[best_label].unique().tolist()\n",
    "        tree = {best_label: {}}  # 生成字典，用于保存树状分类信息；这里不能用self.tree = {}存储\n",
    "        for level in best_label_levels:\n",
    "            level_subdata = self._split_dataSet(dataSet, best_label, level)  # 获取该水平的子数据集\n",
    "            tree[best_label][level] = self.mktree(level_subdata)  # 返回结果\n",
    "        return tree\n",
    "\n",
    "    def predict(self, tree, labels, test_sample):\n",
    "        \"\"\"\n",
    "        对单个样本进行分类\n",
    "        tree: 训练的字典\n",
    "        labels: 除去最后一列的其它字段\n",
    "        test_sample: 需要分类的一行记录数据\n",
    "        \"\"\"\n",
    "        classLabel = None\n",
    "        firstStr = list(tree.keys())[0]  # tree字典里找到第一个用于分类键值对\n",
    "        secondDict = tree[firstStr]\n",
    "        featIndex = labels.index(firstStr)  # 找到第一个建(label)在给定label的索引\n",
    "        for key in secondDict.keys():\n",
    "            if test_sample[featIndex] == key:  # 找到test_sample在当前label下的值\n",
    "                if secondDict[key].__class__.__name__ == \"dict\":\n",
    "                    classLabel = self.predict(secondDict[key], labels, test_sample)\n",
    "                else:\n",
    "                    classLabel = secondDict[key]\n",
    "        return classLabel\n",
    "\n",
    "    def _unit_test(self):\n",
    "        \"\"\"用于测试_entropy函数\"\"\"\n",
    "        data = [\n",
    "            ['青绿', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '是'],  # 1\n",
    "            ['乌黑', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '是'],  # 2\n",
    "            ['乌黑', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '是'],  # 3\n",
    "            ['青绿', '蜷缩', '沉闷', '清晰', '凹陷', '硬滑', '是'],  # 4\n",
    "            ['浅白', '蜷缩', '浊响', '清晰', '凹陷', '硬滑', '是'],  # 5\n",
    "            ['青绿', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '是'],  # 6\n",
    "            ['乌黑', '稍蜷', '浊响', '稍糊', '稍凹', '软粘', '是'],  # 7\n",
    "            ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '硬滑', '是'],  # 8\n",
    "\n",
    "            ['乌黑', '稍蜷', '沉闷', '稍糊', '稍凹', '硬滑', '否'],  # 9\n",
    "            ['青绿', '硬挺', '清脆', '清晰', '平坦', '软粘', '否'],  # 10\n",
    "            ['浅白', '硬挺', '清脆', '模糊', '平坦', '硬滑', '否'],  # 11\n",
    "            ['浅白', '蜷缩', '浊响', '模糊', '平坦', '软粘', '否'],  # 12\n",
    "            ['青绿', '稍蜷', '浊响', '稍糊', '凹陷', '硬滑', '否'],  # 13\n",
    "            ['浅白', '稍蜷', '沉闷', '稍糊', '凹陷', '硬滑', '否'],  # 14\n",
    "            ['乌黑', '稍蜷', '浊响', '清晰', '稍凹', '软粘', '否'],  # 15\n",
    "            ['浅白', '蜷缩', '浊响', '模糊', '平坦', '硬滑', '否'],  # 16\n",
    "            ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑', '否'],  # 17\n",
    "        ]\n",
    "        data = pd.DataFrame(data=data, columns=['色泽','根蒂','敲声','纹理','脐部','触感','分类'])\n",
    "        # return data # 到此行，用于测试_entropy\n",
    "        # return self._split_dataSet(data, \"a\", 1)  # 到此行，用于测试_split_dataSet\n",
    "        # return self._best_split(data)  # 到此行，用于测试_best_split\n",
    "        # return self.mktree(self.dataSet)  # 到此行，用于测试主程序mktree\n",
    "        # 生成树\n",
    "        self.tree = self.mktree(data) # 到此行，用于测试主程序mktree\n",
    "        #打印树\n",
    "        print(self.tree)\n",
    "        labels = ['色泽','根蒂','敲声','纹理','脐部','触感']\n",
    "        #测试样本\n",
    "        test_sample = ['青绿', '蜷缩', '沉闷', '稍糊', '稍凹', '硬滑']\n",
    "        #预测结果\n",
    "        outcome = self.predict(self.tree, labels, test_sample)\n",
    "        print(\"The truth class is %s, The ID3Tree outcome is %s.\" % (\"否\", outcome))\n",
    "model = ID3Tree()\n",
    "model._unit_test()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e59a9ab",
   "metadata": {},
   "source": [
    "## 5.C4.5决策树的构造"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7af7aad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import log\n",
    "import operator\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "376b280f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终构建的C4.5分类树为：\n",
      " {'纹理': {'模糊': '坏瓜', '稍糊': {'触感': {'软粘': '好瓜', '硬滑': '坏瓜'}}, '清晰': {'触感': {'软粘': {'色泽': {'乌黑': '坏瓜', '青绿': {'根蒂': {'硬挺': '坏瓜', '稍蜷': '好瓜'}}}}, '硬滑': '好瓜'}}}}\n"
     ]
    }
   ],
   "source": [
    "dataSet=data\n",
    "def calcShannonEnt(dataSet):\n",
    "    \"\"\"\n",
    "    计算给定数据集的香农熵\n",
    "    :param dataSet:给定的数据集\n",
    "    :return:返回香农熵\n",
    "    \"\"\"\n",
    "    numEntries = len(dataSet)\n",
    "    labelCounts ={}\n",
    "    for featVec in dataSet:\n",
    "        currentLabel = featVec[-1]\n",
    "        if currentLabel not in labelCounts.keys():\n",
    "            labelCounts[currentLabel] =0\n",
    "        labelCounts[currentLabel] += 1\n",
    "    shannonEnt = 0.0\n",
    "    for label in labelCounts.keys():\n",
    "        prob = float(labelCounts[label])/numEntries\n",
    "        shannonEnt -= prob*log(prob,2)\n",
    "    return shannonEnt\n",
    "\n",
    "def majorityCnt(classList):\n",
    "    \"\"\"获取出现次数最好的分类名称\"\"\"\n",
    "    classCount = {}\n",
    "    classList= np.mat(classList).flatten().A.tolist()[0]  # 数据为[['否'], ['是'], ['是']], 转换后为['否', '是', '是']\n",
    "    for vote in classList:\n",
    "        if vote not in classCount.keys():\n",
    "            classCount[vote] = 0\n",
    "        classCount[vote] += 1\n",
    "    sortedClassCount = sorted(classCount.items(),key=operator.itemgetter(1),reverse=True)\n",
    "    return sortedClassCount[0][0]\n",
    "\n",
    "def splitDataSet(dataSet,axis,value):\n",
    "    \"\"\"对离散型特征划分数据集\"\"\"\n",
    "    retDataSet = []  # 创建新的list对象，作为返回的数据\n",
    "    for featVec in dataSet:\n",
    "        if featVec[axis] == value:\n",
    "            reducedFeatVec = featVec[:axis]\n",
    "            reducedFeatVec.extend(featVec[axis+1:])  # 抽取\n",
    "            retDataSet.append(reducedFeatVec)\n",
    "    return retDataSet\n",
    "\n",
    "\n",
    "def splitContinuousDataSet(dataSet, axis, value, direction):\n",
    "    \"\"\"对连续型特征划分数据集\"\"\"\n",
    "    subDataSet = []\n",
    "    for featVec in dataSet:\n",
    "        if direction == 0:\n",
    "            if featVec[axis] > value:  # 按照大于(>)该值进行划分\n",
    "                reduceData = featVec[:axis]\n",
    "                reduceData.extend(featVec[axis + 1:])\n",
    "                subDataSet.append(reduceData)\n",
    "        if direction == 1:\n",
    "            if featVec[axis] <= value:  # 按照小于等于(<=)该值进行划分\n",
    "                reduceData = featVec[:axis]\n",
    "                reduceData.extend(featVec[axis + 1:])\n",
    "                subDataSet.append(reduceData)\n",
    "    return subDataSet\n",
    "\n",
    "def chooseBestFeatureToSplit(dataSet, labels):\n",
    "    \"\"\"选择最好的数据集划分方式\"\"\"\n",
    "    baseEntropy = calcShannonEnt(dataSet)\n",
    "    baseGainRatio = 0.0\n",
    "    bestFeature = -1\n",
    "    numFeatures = len(dataSet[0]) - 1\n",
    "    # 建立一个字典，用来存储每一个连续型特征所对应最佳切分点的具体值\n",
    "    bestSplitDic = {}\n",
    "    # print('dataSet[0]:' + str(dataSet[0]))\n",
    "    for i in range(numFeatures):\n",
    "        # 获取第i个特征的特征值\n",
    "        featVals = [example[i] for example in dataSet]\n",
    "        # 如果该特征时连续型数据\n",
    "        if type(featVals[0]).__name__ == 'float' or type(\n",
    "                featVals[0]).__name__ == 'int':\n",
    "            # 将该特征的所有值按从小到大顺序排序\n",
    "            sortedFeatVals = sorted(featVals)\n",
    "            # 取相邻两样本值的平均数做划分点，共有 len(featVals)-1 个\n",
    "            splitList = []\n",
    "            for j in range(len(featVals) - 1):\n",
    "                splitList.append(\n",
    "                    (sortedFeatVals[j] + sortedFeatVals[j + 1]) / 2.0)\n",
    "            # 遍历每一个切分点\n",
    "            for j in range(len(splitList)):\n",
    "                # 计算该划分方式的条件信息熵newEntropy\n",
    "                newEntropy = 0.0\n",
    "                value = splitList[j]\n",
    "                # 将数据集划分为两个子集\n",
    "                greaterSubDataSet = splitContinuousDataSet(dataSet, i, value, 0)\n",
    "                smallSubDataSet = splitContinuousDataSet(dataSet, i, value, 1)\n",
    "                prob0 = len(greaterSubDataSet) / float(len(dataSet))\n",
    "                newEntropy += prob0 * calcShannonEnt(greaterSubDataSet)\n",
    "                prob1 = len(smallSubDataSet) / float(len(dataSet))\n",
    "                newEntropy += prob1 * calcShannonEnt(smallSubDataSet)\n",
    "                # 计算该划分方式的分裂信息\n",
    "                splitInfo = 0.0\n",
    "                splitInfo -= prob0 * log(prob0, 2)\n",
    "                splitInfo -= prob1 * log(prob1, 2)\n",
    "                # 计算信息增益率 = 信息增益 / 该划分方式的分裂信息\n",
    "                gainRatio = float(baseEntropy - newEntropy) / splitInfo\n",
    "                if gainRatio > baseGainRatio:\n",
    "                    baseGainRatio = gainRatio\n",
    "                    bestSplit = j\n",
    "                    bestFeature = i\n",
    "            bestSplitDic[labels[i]] = splitList[bestSplit]  # 最佳切分点\n",
    "        else:  # 如果该特征时连续型数据\n",
    "            uniqueVals = set(featVals)\n",
    "            splitInfo = 0.0\n",
    "            # 计算每种划分方式的条件信息熵newEntropy\n",
    "            newEntropy = 0.0\n",
    "            for value in uniqueVals:\n",
    "                subDataSet = splitDataSet(dataSet, i, value)\n",
    "                prob = len(subDataSet)/float(len(dataSet))\n",
    "                splitInfo -= prob * log(prob, 2)  # 计算分裂信息\n",
    "                newEntropy += prob * calcShannonEnt(subDataSet)  # 计算条件信息熵\n",
    "            # 若该特征的特征值都相同，说明信息增益和分裂信息都为0，则跳过该特征\n",
    "            if splitInfo == 0.0:\n",
    "                continue\n",
    "            # 计算信息增益率 = 信息增益 / 该划分方式的分裂信息\n",
    "            gainRatio = float(baseEntropy - newEntropy) / splitInfo\n",
    "            if gainRatio > baseGainRatio:\n",
    "                bestFeature = i\n",
    "                baseGainRatio = gainRatio\n",
    "    # 如果最佳切分特征是连续型，则最佳切分点为具体的切分值\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'float' or type(\n",
    "            dataSet[0][bestFeature]).__name__ == 'int':\n",
    "        bestFeatValue = bestSplitDic[labels[bestFeature]]\n",
    "    # 如果最佳切分特征时离散型，则最佳切分点为 切分特征名称,【其实对于离散型特征这个值没有用】\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'str':\n",
    "        bestFeatValue = labels[bestFeature]\n",
    "    # print('bestFeature:' + str(labels[bestFeature]) + ', bestFeatValue:' + str(bestFeatValue))\n",
    "    return bestFeature, bestFeatValue\n",
    "\n",
    "\n",
    "def createTree(dataSet, labels):\n",
    "    \"\"\"创建C4.5树\"\"\"\n",
    "    classList = [example[-1] for example in dataSet]\n",
    "    # 如果类别完全相同，则停止继续划分\n",
    "    if classList.count(classList[0]) == len(classList):\n",
    "        return classList[0]\n",
    "    # 遍历完所有特征时返回出现次数最多的类别\n",
    "    if len(dataSet[0]) == 1:\n",
    "        return majorityCnt(classList)\n",
    "    bestFeature, bestFeatValue = chooseBestFeatureToSplit(dataSet, labels)\n",
    "    if bestFeature == -1:  # 如果无法选出最优分类特征，返回出现次数最多的类别\n",
    "        return majorityCnt(classList)\n",
    "    bestFeatLabel = labels[bestFeature]\n",
    "    myTree = {bestFeatLabel: {}}\n",
    "    subLabels = labels[:bestFeature]\n",
    "    subLabels.extend(labels[bestFeature + 1:])\n",
    "    # 针对最佳切分特征是离散型\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'str':\n",
    "        featVals = [example[bestFeature] for example in dataSet]\n",
    "        uniqueVals = set(featVals)\n",
    "        for value in uniqueVals:\n",
    "            reduceDataSet = splitDataSet(dataSet, bestFeature, value)\n",
    "            # print('reduceDataSet:' + str(reduceDataSet))\n",
    "            myTree[bestFeatLabel][value] = createTree(reduceDataSet, subLabels)\n",
    "            # print(myTree[bestFeatLabel][value])\n",
    "    # 针对最佳切分特征是连续型\n",
    "    if type(dataSet[0][bestFeature]).__name__ == 'int' or type(\n",
    "            dataSet[0][bestFeature]).__name__ == 'float':\n",
    "        # 将数据集划分为两个子集，针对每个子集分别建树\n",
    "        value = bestFeatValue\n",
    "        greaterSubDataSet = splitContinuousDataSet(dataSet, bestFeature, value, 0)\n",
    "        smallSubDataSet = splitContinuousDataSet(dataSet, bestFeature, value, 1)\n",
    "        # print('greaterDataset:' + str(greaterSubDataSet))\n",
    "        # print('smallerDataSet:' + str(smallSubDataSet))\n",
    "        # 针对连续型特征，在生成决策的模块，修改划分点的标签，如“> x.xxx”，\"<= x.xxx\"\n",
    "        myTree[bestFeatLabel]['>' + str(value)] = createTree(greaterSubDataSet,subLabels)\n",
    "        myTree[bestFeatLabel]['<=' + str(value)] = createTree(smallSubDataSet,subLabels)\n",
    "    return myTree\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    dataSet=data_melon\n",
    "    mytree = createTree(dataSet, labels)\n",
    "    print(\"最终构建的C4.5分类树为：\\n\",mytree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8680724b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
